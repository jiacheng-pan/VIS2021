\section{Related Work}\label{sec:relatedwork}
%! related work 的目的，是给审稿人看你的文章到底做了什么，到底哪些工作是跟你类似的，需要在这里跟他们撇清关系。
\subsection{Attributed Node-link Diagram}
Node-link diagrams are widely used to reveal topology and relationships between entities.
We aim to generate descriptions for node-link diagrams with visual encodings, which means the underlying graphs are attributed.
Nobre et al.~\cite{DBLP:journals/cgf/NobreMSL19} surveyed numerous multivariate graph visualization techniques.
Moreover, Partl et al.~\cite{DBLP:conf/biovis/PartlKLKSS12} discussed four categories of attributed node-link diagram layouts.
Node-link diagrams can encode attributes of nodes and links with visual elements.

% 对节点而言，最基础的编码可以将标签编码为文本，将节点的大小编码数值型属性，将节点的颜色编码类别型属性。
% 更复杂的编码中，节点还被编码成一个嵌入的图表，
Node attributes are basically encoded with their size, color, and shape.
Techniques encoding diverse attributes usually embed complex constitutions into one node~\cite{DBLP:conf/infovis/AuberCJM03}.
For example, nodes can be visualized as line charts, box plots, and bar charts in the biology domain~\cite{gehlenborg2010visualization, DBLP:conf/iv/JusufiDK10}.
Photos, icons, or customized glyphs are also often used to encode node attributes~\cite{DBLP:conf/chi/DunneS13}.
Graph visualization tools such as Cytoscape~\cite{DBLP:journals/bioinformatics/FranzLHDSB16}, Gephi~\cite{DBLP:conf/icwsm/BastianHJ09}, NetV.js~\cite{HAN2021} can handle varying degrees of attributes embedding in node-link diagrams.
The layout is also a crucial part of node-link diagrams.
Mostly, node positions are computed by topology-driven layout algorithms~\cite{DBLP:journals/spe/FruchtermanR91, DBLP:journals/cgf/KruigerRMKKT17, DBLP:journals/tvcg/GansnerHN13, DBLP:journals/tvcg/ZhuCHHLZ21} to reveal topology structures.
Attribute-driven layouts are also preferred in several cases.
For example, spatial graphs contain geographic coordinates so that the position of a node can encode the longitude and latitude~\cite{DBLP:journals/tvcg/ElzenW14, DBLP:journals/tvcg/Guo09}.

Visual channels of links such as width~\cite{Katz_2015}, color~\cite{DBLP:journals/tvcg/Guo09}, and dashes~\cite{DBLP:journals/bmcbi/JunkerKS06} can also support attributed links.
For more complex cases, links can incorporate multiple visual elements.
Sch{\"{o}}ffel et al.~\cite{DBLP:conf/iv/SchoffelSE16} encoded the link with bar charts to visualize multiple link attributes.
Abyss Explorer~\cite{DBLP:journals/tvcg/NielsenJBJ09} ``wiggles'' the links and encode attributes of a link with its length.
Compared to nodes, links have less space for attributes encoding.
% 这些工作为我们的工作提供了很多很优秀的案例，我们的工作将会围绕这些案例进行展开，为带有不同编码方案的节点链接图生成相关描述作为标题。
These techniques provide numerous cases for our approach. 
We aim to generate relevant descriptions for node-link diagrams with various encoding schemes.

\subsection{Information Extraction of Visualization}
% ! Data
Numerous methods interpret visualizations by retrieving data from raster images.
Usually, Methods that deal with multi-types of charts provide an algorithm to classify charts in the beginning~\cite{DBLP:conf/icip/GaoZB12, DBLP:conf/chi/JungKSHLKS17, DBLP:conf/eccv/SiegelHLDF16, DBLP:journals/vlc/DaiWNZ18}.
These methods often employ Optical Character Recognition (OCR) to detect textual information from captions, labels, and axes~\cite{DBLP:conf/icip/ZhouT00, DBLP:conf/doceng/HuangT07, DBLP:conf/grec/HuangTL03}.
The combination of OCR techniques and graphics detection techniques facilitates the data retrieving in these methods.
More kinds of charts~\cite{DBLP:conf/pkdd/ClicheRMY17, DBLP:conf/uist/SavvaKCFAH11} are solved by extending these methods to fulfill more diverse tasks.
iVolVER~\cite{DBLP:conf/chi/MendezNV16} supports the transformation of the extracted data to construct interactive animated visualizations.
ReVision~\cite{DBLP:conf/uist/SavvaKCFAH11} populates a gallery of alternative redesigned visualizations through data extraction.
More recently, Chartem~\cite{DBLP:journals/tvcg/FuZCGWZHTZM21} extracts data and embeds it back into the chart to facilitate visualization spread.
More related to graphs, Henkel et al.~\cite{DBLP:conf/vmv/HenkelKLG20} and Lee et al.~\cite{DBLP:conf/icdar/LeeYWH17} retrieved tree-structured data from treemaps and dendrograms.
Several other approaches are proposed to assist individuals with sight impairments~\cite{DBLP:conf/ismis/ChesterE05, DBLP:journals/tiis/CarberrySMDWGCSOM12, DBLP:journals/cgf/ChoiJPCE19}.


% ! Insights
Another type of methods extract insights from visualizations~\cite{DBLP:conf/diagrams/WuCEC10, DBLP:journals/nrhm/DemirOSECMC10} and their underlying data~\cite{DBLP:conf/inlg/ObeidH20, DBLP:journals/ivs/CuiBYE19}.
Demiralp et al.~\cite{DBLP:journals/pvldb/DemiralpHPP17} defined \textit{insights} as a strong manifestation of the data or the visualization.
Different methods have different preferences according to their inputs.
For example, inputs of Chart-to-Text~\cite{DBLP:conf/inlg/ObeidH20} mainly come from the underlying data.
In contrast, Wu et al.~\cite{DBLP:conf/diagrams/WuCEC10} and Demir et al.~\cite{DBLP:journals/nrhm/DemirOSECMC10} employed visual features.
They recommended the potential intention of line charts and bar charts by detecting the most significant features.
AutoCaption~\cite{DBLP:conf/apvis/LiuXHWY20} first parses textual and visual components to a formatted information table incorporating the underlying data.
Then it extracts a set of pre-defined features as insights from the table.
Several works employ the extracted insights to augment visualizations by annotation~\cite{DBLP:conf/ieeevast/Kandogan12, DBLP:journals/tvcg/BryanMW17}, overlays~\cite{DBLP:journals/tvcg/KongA12},  and widgets~\cite{DBLP:journals/tvcg/SrinivasanDES19}.
% Kandongan~\cite{DBLP:conf/ieeevast/Kandogan12} introduced the concept of just-in-time descriptive analytics to help users understand data in point-based visualizations (e.g., scatter plots, line charts, et cetera). 
% The fundamental is to identify clusters, outliers, and trends from visualizations.
% Srinivasan et al. presented Voder~\cite{DBLP:journals/tvcg/SrinivasanDES19}, a system to generate data facts (descriptions of data statistics) based on a basic set of heuristics.
% Then the facts are used as interactive widgets to improve user interpretion.
% Graphical Overlays~\cite{DBLP:journals/tvcg/KongA12} takes the insights to generate graphical overlays on charts to draw the viewer's attention.

These two categories of methods retrieve the underlying data from visualization results and generate insights from the extracted information. 
They mainly focus on classical charts such as line charts, bar charts, and pie charts.
We concern more about the constituents of a node-link diagram, such as its visual encodings and layout.

%! visual mapping
Poco and Heer~\cite{DBLP:journals/cgf/PocoH17} proposed a reverse-engineering approach to recover visual encodings from area charts, bar charts, line charts, and scatter plots. 
However, they did not infer visual channels such as color, shape, size, et cetera.
Then they complemented the lack of color mapping by employing OCT techniques to detect continuous legends~\cite{DBLP:journals/tvcg/PocoMH18} and discrete legends~\cite{DBLP:conf/sibgrapi/MayhuaNHP18}.
Yuan et al.~\cite{DBLP:journals/corr/abs-2103-00741} presented a deep learning method to detect the color mappings without textual-legends.
These methods mainly extract visual encodings from raster images, but with the emergence of D3~\cite{DBLP:journals/tvcg/BostockOH11}, web-based visualization is more popular now.
Visual encodings extraction can be more diverse and accurate with the data binding feature of D3.
Harper and Agrawala~\cite{DBLP:conf/uist/HarperA14} introduced a tool to deconstruct D3 visualizations by extracting the bound data, markers, and visual mappings. 
They enhanced the tool to identify textual information and employed it to generate reusable style templates~\cite{DBLP:journals/tvcg/HarperA18} followed by Hoque and Agrawala~\cite{DBLP:journals/tvcg/HoqueA20}. % enhanced the tool again with more detection target such as angles, arcs, and so on. With the tool, they presented a search engine that can index D3 visualizations based on the extarcted information.

% 这些方法或是只适用于检测基础的可视化图表如bar chart/line chart/area chart等，或是只适用于对d3等具有数据绑定的svg进行编码提取。
% 我们提出了对节点链接图进行信息提取的方法，该方法从多个角度出发，适用于通用的svg场景，而不需要数据绑定的前提。
Methods that extract visual mappings from raster images~\cite{DBLP:journals/cgf/PocoH17, DBLP:journals/tvcg/PocoMH18, DBLP:conf/sibgrapi/MayhuaNHP18, DBLP:journals/corr/abs-2103-00741} can be more capable to common cases, but they are primarily designed for basic charts or only can detect several pre-defined visual mapping types.
Whereas methods that deconstruct D3 visualizations~\cite{DBLP:conf/uist/HarperA14, DBLP:journals/tvcg/HarperA18, DBLP:journals/tvcg/HoqueA20} can be applied to more kinds of visual mappings, but they require the data binding feature of D3 so that data can be retrieved for visual elements. We proposed a method that supports extracting visual encodings for SVG-formatted node-link diagrams without data bound to visual elements.

\subsection{Automatic Description for Visualization}
Approaches that generate descriptions for visualizations are mainly based on the extracted information.
Mittal et al.~\cite{DBLP:journals/coling/MittalMCR98} developed a caption generation system with natural language generation techniques to describe mappings between data and marks.
Similarly, iGraph-Lite~\cite{DBLP:journals/tochi/FerresLST13} generates template-based descriptions of the appearance of the chart.
More approaches pay attention to generating descriptions of extracted insights.
Chart-to-Text~\cite{DBLP:conf/inlg/ObeidH20} generates natural language descriptions for line charts and bar charts using the transformer model~\cite{DBLP:conf/nips/VaswaniSPUJGKP17}. 
Similarly, AutoCaption~\cite{DBLP:conf/apvis/LiuXHWY20} fills the extracted insights into templates to generate captions about trends, maximum values, clusters, et cetera. 
% 一些工作通过回答问题的方式来提取insight.
Several approaches generate descriptions by answering questions about visualizations.~\cite{DBLP:conf/cvpr/KaflePCK18, DBLP:conf/chi/KimHA20, DBLP:conf/eccv/KembhaviSKSHF16}.
Kembhavi et al.~\cite{DBLP:conf/eccv/KembhaviSKSHF16} interpreted the relationships among multiple scientific diagrams in one picture. 
A dataset called DVQA~\cite{DBLP:conf/cvpr/KaflePCK18} is presented with more than 3 million image-question pairs about bar charts to support bar chart question answering. 
An end-to-end neural network and a dynamic local dictionary are designed to indicate the ability of the dataset.
More recently, Kim et al.~\cite{DBLP:conf/chi/KimHA20} introduced an automatic question answering pipeline to answering natural language questions about bar charts and line charts. It extends Sempre~\cite{DBLP:conf/acl/PasupatL15, DBLP:conf/emnlp/ZhangPL17} to answer questions about charts with Vega-Lite~\cite{DBLP:journals/tvcg/SatyanarayanMWH17} format and give visual explanations.

None of these approaches is tailored for generating descriptions for node-link diagrams. 
We propose an approach named \ApproachName~to generate descriptions for node-link diagrams automatically.
It utilizes three information extraction pipelines to detect crucial information from the source code and data and generates template-based descriptions.